{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:13:38.070738Z","iopub.execute_input":"2022-01-16T12:13:38.071219Z","iopub.status.idle":"2022-01-16T12:13:38.877871Z","shell.execute_reply.started":"2022-01-16T12:13:38.071062Z","shell.execute_reply":"2022-01-16T12:13:38.876821Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Get helper_functions.py script from course GitHub\n!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py \n\n# Import helper functions we're going to use\nfrom helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:13:38.880345Z","iopub.execute_input":"2022-01-16T12:13:38.880849Z","iopub.status.idle":"2022-01-16T12:13:45.634620Z","shell.execute_reply.started":"2022-01-16T12:13:38.880787Z","shell.execute_reply":"2022-01-16T12:13:45.633659Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"In this notebook, we're going to continue to work with smaller subsets of the data, except this time we'll have a look at how we can use the in-built pretrained models within the tf.keras.applications module as well as how to fine-tune them to our own custom dataset.\n\nWe'll also practice using a new but similar dataloader function to what we've used before, image_dataset_from_directory() which is part of the tf.keras.preprocessing module.\n\nFinally, we'll also be practicing using the Keras Functional API for building deep learning models. The Functional API is a more flexible way to create models than the tf.keras.Sequential API","metadata":{}},{"cell_type":"code","source":"# Get 10% of the data of the 10 classes\n!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip \n\nunzip_data(\"10_food_classes_10_percent.zip\")","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:13:45.636013Z","iopub.execute_input":"2022-01-16T12:13:45.636324Z","iopub.status.idle":"2022-01-16T12:13:51.946132Z","shell.execute_reply.started":"2022-01-16T12:13:45.636281Z","shell.execute_reply":"2022-01-16T12:13:51.945097Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"walk_through_dir(\"10_food_classes_10_percent\")","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:13:51.949231Z","iopub.execute_input":"2022-01-16T12:13:51.949554Z","iopub.status.idle":"2022-01-16T12:13:51.971930Z","shell.execute_reply.started":"2022-01-16T12:13:51.949510Z","shell.execute_reply":"2022-01-16T12:13:51.970358Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_dir = \"10_food_classes_10_percent/train/\"\ntest_dir = \"10_food_classes_10_percent/test/\"","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:13:51.973273Z","iopub.execute_input":"2022-01-16T12:13:51.973676Z","iopub.status.idle":"2022-01-16T12:13:51.979395Z","shell.execute_reply.started":"2022-01-16T12:13:51.973633Z","shell.execute_reply":"2022-01-16T12:13:51.978196Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"One of the main benefits of using tf.keras.prepreprocessing.image_dataset_from_directory() rather than ImageDataGenerator is that it creates a tf.data.Dataset object rather than a generator. The main advantage of this is the tf.data.Dataset API is much more efficient (faster) than the ImageDataGenerator API which is paramount for larger datasets.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimg_size =(224,224)\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(directory = train_dir,\n                                                                image_size = img_size,\n                                                                 batch_size =32,\n                                                                label_mode = \"categorical\")\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(directory = test_dir,\n                                                                image_size = img_size,\n                                                                 batch_size =32,\n                                                                label_mode = \"categorical\")","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:13:51.981075Z","iopub.execute_input":"2022-01-16T12:13:51.983076Z","iopub.status.idle":"2022-01-16T12:13:56.589607Z","shell.execute_reply.started":"2022-01-16T12:13:51.983033Z","shell.execute_reply":"2022-01-16T12:13:56.588647Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:13:56.591283Z","iopub.execute_input":"2022-01-16T12:13:56.591903Z","iopub.status.idle":"2022-01-16T12:13:56.606922Z","shell.execute_reply.started":"2022-01-16T12:13:56.591858Z","shell.execute_reply":"2022-01-16T12:13:56.605283Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"In the above output:\n\n- (None, 224, 224, 3) refers to the tensor shape of our images where None is the batch size, 224 is the height (and width) and 3 is the color channels (red, green, blue).\n- (None, 10) refers to the tensor shape of the labels where None is the batch size and 10 is the number of possible labels (the 10 different food classes).\n- Both image tensors and labels are of the datatype tf.float32.\n\nThe batch_size is None due to it only being used during model training. You can think of None as a placeholder waiting to be filled with the batch_size parameter from image_dataset_from_directory().\n\nAnother benefit of using the tf.data.Dataset API are the assosciated methods which come with it.\n\nFor example, if we want to find the name of the classes we were working with, we could use the class_names attribute.","metadata":{}},{"cell_type":"code","source":"train_data.class_names","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:13:56.608156Z","iopub.execute_input":"2022-01-16T12:13:56.608423Z","iopub.status.idle":"2022-01-16T12:13:56.627404Z","shell.execute_reply.started":"2022-01-16T12:13:56.608385Z","shell.execute_reply":"2022-01-16T12:13:56.626026Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"To do so we're going to be using the tf.keras.applications module as it contains a series of already trained (on ImageNet) computer vision models as well as the Keras Functional API to construct our model.\n\nWe're going to go through the following steps:\n\n- Instantiate a pre-trained base model object by choosing a target model such as EfficientNetB0 from tf.keras.applications, setting the - include_top parameter to False (we do this because we're going to create our own top, which are the output layers for the model).\n- Set the base model's trainable attribute to False to freeze all of the weights in the pre-trained model.\n- Define an input layer for our model, for example, what shape of data should our model expect?\n- [Optional] Normalize the inputs to our model if it requires. Some computer vision models such as ResNetV250 require their inputs to be between 0 & 1.","metadata":{}},{"cell_type":"code","source":"# 1. create a base model with tf.keras.applications\nbase_model = tf.keras.applications.EfficientNetB0(include_top=False)\n\n# 2 Freeze the base model(so the pre learned patterns remain the same)\nbase_model.trainable = False\n\n# 3 create inputs into the base model\ninputs = tf.keras.layers.Input(shape=(224,224,3),name =\"input_layer\")\n\n# 4. If using ResNet50V2, add this to speed up convergence, remove for EfficientNet\n# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n\n# Pass the inputs to the base model\nx = base_model(inputs)\n# check the data shape after passing it to base_model\nprint(f\"shape after base_model: {x.shape}\")\n\n# 6 average pool the outtputs of the base model( aggregate all the most important info, reduce number of computation)\nx = tf.keras.layers.GlobalAveragePooling2D(name=\"gap_layer\")(x)\nprint(f\"shape after averaging: {x.shape}\")\n\n#7 create an activation layer\noutput = tf.keras.layers.Dense(10,activation=\"softmax\", name =\"out_layer\")(x)\n\nmodel_0 = tf.keras.Model(inputs,output)\n\nmodel_0.compile(loss ='categorical_crossentropy',\n               optimizer = tf.keras.optimizers.Adam(),\n               metrics =['accuracy'])\nhist_0 = model_0.fit(train_data,\n                    epochs =5,\n                    validation_data = test_data,\n                    callbacks=[create_tensorboard_callback(\"transfer_learning\",\"10_per_feature_ext\")])","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:13:56.629366Z","iopub.execute_input":"2022-01-16T12:13:56.629789Z","iopub.status.idle":"2022-01-16T12:15:02.471962Z","shell.execute_reply.started":"2022-01-16T12:13:56.629709Z","shell.execute_reply":"2022-01-16T12:15:02.471034Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"After a minute or so of training our model performs incredibly well on both the training (87%+ accuracy) and test sets (~83% accuracy).\n\nThis is incredible. All thanks to the power of transfer learning.\n\nIt's important to note the kind of transfer learning we used here is called feature extraction transfer learning, similar to what we did with the TensorFlow Hub models.\n\nIn other words, we passed our custom data to an already pre-trained model (EfficientNetB0), asked it \"what patterns do you see?\" and then put our own output layer on top to make sure the outputs were tailored to our desired number of classes.\n\nWe also used the Keras Functional API to build our model rather than the Sequential API. For now, the benefits of this main not seem clear but when you start to build more sophisticated models, you'll probably want to use the Functional API. So it's important to have exposure to this way of building models.","metadata":{}},{"cell_type":"code","source":"for layer_number,layer in enumerate(model_0.layers):\n    print(layer_number,layer.name)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:15:02.476792Z","iopub.execute_input":"2022-01-16T12:15:02.477050Z","iopub.status.idle":"2022-01-16T12:15:02.485049Z","shell.execute_reply.started":"2022-01-16T12:15:02.477017Z","shell.execute_reply":"2022-01-16T12:15:02.483734Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"base_model.summary(0)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:15:02.486927Z","iopub.execute_input":"2022-01-16T12:15:02.487863Z","iopub.status.idle":"2022-01-16T12:15:02.658246Z","shell.execute_reply.started":"2022-01-16T12:15:02.487800Z","shell.execute_reply":"2022-01-16T12:15:02.657261Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model_0.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:15:02.659387Z","iopub.execute_input":"2022-01-16T12:15:02.659958Z","iopub.status.idle":"2022-01-16T12:15:02.688913Z","shell.execute_reply.started":"2022-01-16T12:15:02.659908Z","shell.execute_reply":"2022-01-16T12:15:02.687980Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(hist_0)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:15:02.690670Z","iopub.execute_input":"2022-01-16T12:15:02.691095Z","iopub.status.idle":"2022-01-16T12:15:03.548961Z","shell.execute_reply.started":"2022-01-16T12:15:02.691053Z","shell.execute_reply":"2022-01-16T12:15:03.547941Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Getting a feature vector from a trained model\n\nThe tf.keras.layers.GlobalAveragePooling2D() layer transforms a 4D tensor into a 2D tensor by averaging the values across the inner-axes.\n","metadata":{}},{"cell_type":"code","source":"# practical\ninput_shape =(1,4,5,3)\n\n#create a random tensor\ntf.random.set_seed(42)\ninput_tensor = tf.random.normal(input_shape)\nprint(\"Random input tensor:\\n {}\".format(input_tensor))","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:15:03.550862Z","iopub.execute_input":"2022-01-16T12:15:03.551225Z","iopub.status.idle":"2022-01-16T12:15:03.583017Z","shell.execute_reply.started":"2022-01-16T12:15:03.551177Z","shell.execute_reply":"2022-01-16T12:15:03.581905Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"gapt = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\nprint(f\"2d global average : {gapt}\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:15:03.585334Z","iopub.execute_input":"2022-01-16T12:15:03.586037Z","iopub.status.idle":"2022-01-16T12:15:03.595324Z","shell.execute_reply.started":"2022-01-16T12:15:03.585986Z","shell.execute_reply":"2022-01-16T12:15:03.594101Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Check the shapes of the different tensors\nprint(f\"Shape of input tensor: {input_tensor.shape}\")\nprint(f\"Shape of 2D global averaged pooled input tensor: {gapt.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:15:03.597302Z","iopub.execute_input":"2022-01-16T12:15:03.598004Z","iopub.status.idle":"2022-01-16T12:15:03.607209Z","shell.execute_reply.started":"2022-01-16T12:15:03.597954Z","shell.execute_reply":"2022-01-16T12:15:03.605990Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Running a series of transfer learning experiments\nWe've seen the incredible results of transfer learning on 10% of the training data, what about 1% of the training data?\n\nWhat kind of results do you think we can get using 100x less data than the original CNN models we built ourselves?\n\nWhy don't we answer that question while running the following modelling experiments:\n\n- model_1: Use feature extraction transfer learning on 1% of the training data with data augmentation.\n- model_2: Use feature extraction transfer learning on 10% of the training data with data augmentation.\n- model_3: Use fine-tuning transfer learning on 10% of the training data with data augmentation.\n- model_4: Use fine-tuning transfer learning on 100% of the training data with data augmentation.\n\nWhile all of the experiments will be run on different versions of the training data, they will all be evaluated on the same test dataset, this ensures the results of each experiment are as comparable as possible.\n\nAll experiments will be done using the EfficientNetB0 model within the tf.keras.applications module.\n\nTo make sure we're keeping track of our experiments, we'll use our create_tensorboard_callback() function to log all of the model training logs.\n\nWe'll construct each model using the Keras Functional API and instead of implementing data augmentation in the ImageDataGenerator class as we have previously, we're going to build it right into the model using the tf.keras.layers.experimental.preprocessing module.","metadata":{}},{"cell_type":"code","source":"# Download and unzip data\n!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\nunzip_data(\"10_food_classes_1_percent.zip\")\n\n# Create training and test dirs\ntrain_dir_1 = \"10_food_classes_1_percent/train/\"\ntest_dir_1 = \"10_food_classes_1_percent/test/\"","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:15:03.608731Z","iopub.execute_input":"2022-01-16T12:15:03.608969Z","iopub.status.idle":"2022-01-16T12:15:07.533200Z","shell.execute_reply.started":"2022-01-16T12:15:03.608939Z","shell.execute_reply":"2022-01-16T12:15:07.531933Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_1_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir_1,\n                                                                  batch_size=32,\n                                                                  label_mode ='categorical',\n                                                                  image_size = img_size)\ntest_1_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir_1,\n                                                                 label_mode =\"categorical\",\n                                                                 image_size=img_size)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:15:07.535378Z","iopub.execute_input":"2022-01-16T12:15:07.535734Z","iopub.status.idle":"2022-01-16T12:15:07.908285Z","shell.execute_reply.started":"2022-01-16T12:15:07.535700Z","shell.execute_reply":"2022-01-16T12:15:07.907293Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"#### Adding data augmentation right into the model\nPreviously we've used the different parameters of the ImageDataGenerator class to augment our training images, this time we're going to build data augmentation right into the model.\n\nUsing the tf.keras.layers.experimental.preprocessing module and creating a dedicated data augmentation layer.\n\nThis a relatively new feature added to TensorFlow 2.2+ but it's very powerful. Adding a data augmentation layer to the model has the following benefits:\n\nPreprocessing of the images (augmenting them) happens on the GPU rather than on the CPU (much faster).\nImages are best preprocessed on the GPU where as text and structured data are more suited to be preprocessed on the CPU.\nImage data augmentation only happens during training so we can still export our whole model and use it elsewhere. And if someone else wanted to train the same model as us, including the same kind of data augmentation, they could.\n![](https://camo.githubusercontent.com/447f1219430b6a60d99b64c37f9514dc84fa1b55/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6d7264626f75726b652f74656e736f72666c6f772d646565702d6c6561726e696e672f6d61696e2f696d616765732f30352d646174612d6175676d656e746174696f6e2d696e736964652d612d6d6f64656c2e706e67)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow import keras\n\n# create a data augmentation stage with horizontal flipping, rotation and zooms\ndata_augmentation = keras.Sequential([\n    preprocessing.RandomFlip(\"horizontal\"),\n    preprocessing.RandomRotation(0.2),\n    preprocessing.RandomZoom(0.2),\n    preprocessing.RandomHeight(0.2),\n    preprocessing.RandomWidth(0.2)\n    # preprocessing.rescaling(1./255) # for resnet\n], name =\"data_aug\")","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:15:07.909874Z","iopub.execute_input":"2022-01-16T12:15:07.910198Z","iopub.status.idle":"2022-01-16T12:15:07.940797Z","shell.execute_reply.started":"2022-01-16T12:15:07.910159Z","shell.execute_reply":"2022-01-16T12:15:07.939912Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport os\nimport random\ntarget_class = random.choice(train_1_data.class_names)# choose a random class\ntarget_dir = \"10_food_classes_1_percent/train/\"+target_class\nrandom_image = random.choice(os.listdir(target_dir)) # choose a random image from target directory\nrandom_image_path = target_dir + \"/\" + random_image # create the choosen random image path\nimg = mpimg.imread(random_image_path) # read in the chosen target image\nplt.imshow(img) # plot the target image\nplt.title(f\"Original random image from class: {target_class}\")\nplt.axis(False); # turn off the axes\n\n# Augment the image\naugmented_img = data_augmentation(tf.expand_dims(img, axis=0)) # data augmentation model requires shape (None, height, width, 3)\nplt.figure()\nplt.imshow(tf.squeeze(augmented_img)/255.) # requires normalization after augmentation\nplt.title(f\"Augmented random image from class: {target_class}\")\nplt.axis(False);","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:15:07.942239Z","iopub.execute_input":"2022-01-16T12:15:07.943151Z","iopub.status.idle":"2022-01-16T12:15:08.663444Z","shell.execute_reply.started":"2022-01-16T12:15:07.943105Z","shell.execute_reply":"2022-01-16T12:15:08.662539Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Model 1: Feature extraction transfer learning on 1% of the data with data augmentation","metadata":{}},{"cell_type":"code","source":"input_shape =(224,224,3)\nbase_model = tf.keras.applications.EfficientNetB0(include_top=False)\nbase_model.trainable =False\n\n#create a input layer\ninputs = layers.Input(shape = input_shape,name='inp_layer')\n\n#add in data augmentation sequential model as layer\nx = data_augmentation(inputs)\n\n# give the base model inputs and dont train it\nx = base_model(x,training=False)\n\n# pool outpu features of base model\nx = layers.GlobalAveragePooling2D(name =\"gap_layer_1\")(x)\n\n# put a dense layer on as output\noutput = layers.Dense(10,activation='Softmax',name =\"out_layer\")(x)\n\n# make a model with inputs and outputs\nmodel_1 = keras.Model(inputs,output)\n\nmodel_1.compile(loss =\"categorical_crossentropy\",\n               optimizer = tf.keras.optimizers.Adam(),\n               metrics=['accuracy'])\n\nhist_1 = model_1.fit(train_1_data,\n                    epochs = 5,\n                    validation_data = test_1_data,\n                    callbacks=[create_tensorboard_callback(\"transfer_learning\", \"1_percent_data_aug\")])","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:15:08.664982Z","iopub.execute_input":"2022-01-16T12:15:08.665452Z","iopub.status.idle":"2022-01-16T12:16:10.541449Z","shell.execute_reply.started":"2022-01-16T12:15:08.665397Z","shell.execute_reply":"2022-01-16T12:16:10.540340Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model_1.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:16:10.545314Z","iopub.execute_input":"2022-01-16T12:16:10.545554Z","iopub.status.idle":"2022-01-16T12:16:10.572785Z","shell.execute_reply.started":"2022-01-16T12:16:10.545523Z","shell.execute_reply":"2022-01-16T12:16:10.571140Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"\nThere it is. We've now got data augmentation built right into the our model. This means if we saved it and reloaded it somewhere else, the data augmentation layers would come with it.\n\nThe important thing to remember is data augmentation only runs during training. So if we were to evaluate or use our model for inference (predicting the class of an image) the data augmentation layers will be automatically turned off.","metadata":{}},{"cell_type":"code","source":"plot_loss_curves(hist_1)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:16:10.574307Z","iopub.execute_input":"2022-01-16T12:16:10.574641Z","iopub.status.idle":"2022-01-16T12:16:11.140580Z","shell.execute_reply.started":"2022-01-16T12:16:10.574579Z","shell.execute_reply":"2022-01-16T12:16:11.139650Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Model 2: Feature extraction transfer learning with 10 percent of the data and data augmentation\n\n*From a practical standpoint, as we've talked about before, you'll want to reduce the amount of time between your initial experiments as much as possible. In other words, run a plethora of smaller experiments, using less data and less training iterations before you find something promising and then scale it up.*","metadata":{}},{"cell_type":"code","source":"train_dir_10_percent = \"10_food_classes_10_percent/train/\"\ntest_dir = \"10_food_classes_10_percent/test/\"","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:16:11.142343Z","iopub.execute_input":"2022-01-16T12:16:11.142941Z","iopub.status.idle":"2022-01-16T12:16:11.149063Z","shell.execute_reply.started":"2022-01-16T12:16:11.142894Z","shell.execute_reply":"2022-01-16T12:16:11.147997Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"img_size =(224,224)\ntrain_data_10 = tf.keras.preprocessing.image_dataset_from_directory(train_dir_10_percent,\n                                                                   label_mode='categorical',\n                                                                   image_size = img_size)\ntest_data_10 = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n                                                                   label_mode='categorical',\n                                                                   image_size = img_size)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:16:11.151033Z","iopub.execute_input":"2022-01-16T12:16:11.151528Z","iopub.status.idle":"2022-01-16T12:16:11.532090Z","shell.execute_reply.started":"2022-01-16T12:16:11.151479Z","shell.execute_reply":"2022-01-16T12:16:11.531015Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\n\ndata_aug = Sequential([\n    preprocessing.RandomFlip('horizontal'),\n    preprocessing.RandomHeight(0.2),\n    preprocessing.RandomRotation(0.2),\n    preprocessing.RandomWidth(0.2),\n    preprocessing.RandomZoom(0.2),\n],name=\"data augmentation\")\n\ninput_shape = (224,224, 3)\n\nbase_model = tf.keras.applications.EfficientNetB0(include_top = False)\nbase_model.trainable =False\n\ninputs = layers.Input(shape =input_shape,name =\"input_layer\")\nx = data_augmentation(inputs)\nx = base_model(x,training=False)\nx = layers.GlobalAveragePooling2D(name='GAPL')(x)\noutputs = layers.Dense(10,activation=\"softmax\",name=\"output_layer\")(x)\nmodel_2 = tf.keras.Model(inputs,outputs)\nmodel_2.compile(loss ='categorical_crossentropy',\n               optimizer =tf.keras.optimizers.Adam(learning_rate =0.001),\n               metrics =['accuracy'])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:16:11.534062Z","iopub.execute_input":"2022-01-16T12:16:11.534545Z","iopub.status.idle":"2022-01-16T12:16:14.706130Z","shell.execute_reply.started":"2022-01-16T12:16:11.534502Z","shell.execute_reply":"2022-01-16T12:16:14.705069Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"#### Creating a ModelCheckpoint callback\n\nThe ModelCheckpoint callback gives you the ability to save your model, as a whole in the SavedModel format or the weights (patterns) only to a specified directory as it trains.\n\nThis is helpful if you think your model is going to be training for a long time and you want to make backups of it as it trains. It also means if you think your model could benefit from being trained for longer, you can reload it from a specific checkpoint and continue training from there.\n\nFor example, say you fit a feature extraction transfer learning model for 5 epochs and you check the training curves and see it was still improving and you want to see if fine-tuning for another 5 epochs could help, you can load the checkpoint, unfreeze some (or all) of the base model layers and then continue training.\n\nThe SavedModel format saves a model's architecture, weights and training configuration all in one folder. It makes it very easy to reload your model exactly how it is elsewhere. However, if you do not want to share all of these details with others, you may want to save and share the weights only (these will just be large tensors of non-human interpretable numbers). If disk space is an issue, saving the weights only is faster and takes up less space than saving the whole model.\n\n\n\n","metadata":{}},{"cell_type":"code","source":"#SET THE CHECKPOINT PATH\ncheckpoint_path = \"Ten_per/check.ckpt\"\ncheck_callback = tf.keras.callbacks.ModelCheckpoint(filepath =checkpoint_path,\n                                                   save_weights_only =True,# set false to save entire model\n                                                   save_best_only =False, # set true to save only the best model\n                                                   save_freq ='epoch',# save every epoch\n                                                   verbose =1)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:16:14.707831Z","iopub.execute_input":"2022-01-16T12:16:14.708121Z","iopub.status.idle":"2022-01-16T12:16:14.714530Z","shell.execute_reply.started":"2022-01-16T12:16:14.708081Z","shell.execute_reply":"2022-01-16T12:16:14.713476Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"initial_epochs =5\nhist_10 = model_2.fit(train_data_10,\n                     epochs =initial_epochs,\n                     validation_data =test_data_10,\n                     validation_steps = int(0.25*len(test_data_10)),\n                     callbacks=check_callback\n                     )","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:16:14.722387Z","iopub.execute_input":"2022-01-16T12:16:14.723205Z","iopub.status.idle":"2022-01-16T12:17:08.068822Z","shell.execute_reply.started":"2022-01-16T12:16:14.723171Z","shell.execute_reply":"2022-01-16T12:17:08.067661Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"result_10_aug = model_2.evaluate(test_data_10)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:08.071050Z","iopub.execute_input":"2022-01-16T12:17:08.071377Z","iopub.status.idle":"2022-01-16T12:17:18.326712Z","shell.execute_reply.started":"2022-01-16T12:17:08.071330Z","shell.execute_reply":"2022-01-16T12:17:18.325672Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"result_10_aug","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:18.328797Z","iopub.execute_input":"2022-01-16T12:17:18.329130Z","iopub.status.idle":"2022-01-16T12:17:18.336554Z","shell.execute_reply.started":"2022-01-16T12:17:18.329083Z","shell.execute_reply":"2022-01-16T12:17:18.335487Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(hist_10)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:18.338469Z","iopub.execute_input":"2022-01-16T12:17:18.339161Z","iopub.status.idle":"2022-01-16T12:17:18.909264Z","shell.execute_reply.started":"2022-01-16T12:17:18.339099Z","shell.execute_reply":"2022-01-16T12:17:18.908252Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# loading the checkpoint saved models\nmodel_2.load_weights(checkpoint_path)\nloaded_weights_model_results = model_2.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:18.911134Z","iopub.execute_input":"2022-01-16T12:17:18.911509Z","iopub.status.idle":"2022-01-16T12:17:26.204280Z","shell.execute_reply.started":"2022-01-16T12:17:18.911420Z","shell.execute_reply":"2022-01-16T12:17:26.203181Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Model 3: Fine-tuning an existing model on 10% of the data\n\n![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/05-fine-tuning-an-efficientnet-model.png)\n                        Input(Bottom)---------------------------->output(TOP)\n\n*High-level example of fine-tuning an EfficientNet model. Bottom layers (layers closer to the input data) stay frozen where as top layers (layers closer to the output data) are updated during training.*\n\nSo far our saved model has been trained using feature extraction transfer learning for 5 epochs on 10% of the training data and data augmentation.\n\nThis means all of the layers in the base model (EfficientNetB0) were frozen during training.\n\nNow switching to fine-tuning transfer learning. This means we'll be using the same base model except we'll be unfreezing some of its layers (ones closest to the top) and running the model for a few more epochs.\n\nThe idea with fine-tuning is to start customizing the pre-trained model more to our own data.\n\n> Fine-tuning usually works best *after* training a feature extraction model for a few epochs and with large amounts of data. For more on this, check out [Keras' guide on Transfer learning & fine-tuning](https://keras.io/guides/transfer_learning/).\n\n","metadata":{}},{"cell_type":"code","source":"#layers in the loaded model\nmodel_2.layers","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:26.206231Z","iopub.execute_input":"2022-01-16T12:17:26.206774Z","iopub.status.idle":"2022-01-16T12:17:26.214388Z","shell.execute_reply.started":"2022-01-16T12:17:26.206710Z","shell.execute_reply":"2022-01-16T12:17:26.213228Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"for layers in model_2.layers:\n    print(layer.trainable)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:26.220961Z","iopub.execute_input":"2022-01-16T12:17:26.222925Z","iopub.status.idle":"2022-01-16T12:17:26.231961Z","shell.execute_reply.started":"2022-01-16T12:17:26.222861Z","shell.execute_reply":"2022-01-16T12:17:26.230484Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model_2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:26.234182Z","iopub.execute_input":"2022-01-16T12:17:26.235816Z","iopub.status.idle":"2022-01-16T12:17:26.283344Z","shell.execute_reply.started":"2022-01-16T12:17:26.235767Z","shell.execute_reply":"2022-01-16T12:17:26.282324Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# How many layers are trainable in our base model?\nprint(len(model_2.layers[2].trainable_variables)) # layer at index 2 is the EfficientNetB0 layer (the base model)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:26.288288Z","iopub.execute_input":"2022-01-16T12:17:26.290960Z","iopub.status.idle":"2022-01-16T12:17:26.300949Z","shell.execute_reply.started":"2022-01-16T12:17:26.290920Z","shell.execute_reply":"2022-01-16T12:17:26.299846Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"print(len(base_model.trainable_variables))","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:26.302885Z","iopub.execute_input":"2022-01-16T12:17:26.303935Z","iopub.status.idle":"2022-01-16T12:17:26.312905Z","shell.execute_reply.started":"2022-01-16T12:17:26.303546Z","shell.execute_reply":"2022-01-16T12:17:26.311129Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Hence we can confirm that the base layers are not trainable \n# we can check each layer in the base model to verify which is trainable\nfor layer_number,layer in enumerate(base_model.layers):\n    print(layer_number,layer.name, layer.trainable)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:26.315865Z","iopub.execute_input":"2022-01-16T12:17:26.317237Z","iopub.status.idle":"2022-01-16T12:17:26.387403Z","shell.execute_reply.started":"2022-01-16T12:17:26.317190Z","shell.execute_reply":"2022-01-16T12:17:26.386735Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Now to fine-tune the base model to our own data, we're going to unfreeze the top 10 layers and continue training our model for another 5 epochs.\n\nThis means all of the base model's layers except for the last 10 will remain frozen and untrainable. And the weights in the remaining unfrozen layers will be updated during training.\n\nIdeally, we should see the model's performance improve.\n\nThere's no set rule for this. You could unfreeze every layer in the pretrained model or you could try unfreezing one layer at a time. Best to experiment with different amounts of unfreezing and fine-tuning to see what happens. Generally, the less data you have, the less layers you want to unfreeze and the more gradually you want to fine-tune.\n\nTo begin fine-tuning, we'll unfreeze the entire base model by setting its `trainable` attribute to `True`. Then we'll refreeze every layer in the base model except for the last 10 by looping through them and setting their `trainable` attribute to `False`. Finally, we'll recompile the model.","metadata":{}},{"cell_type":"code","source":"base_model.trainable =True\n\n#refreeze \nfor layer in base_model.layers[:-10]:\n    layer.trainable=False\n\nmodel_2.compile(loss = \"categorical_crossentropy\",\n               optimizer =tf.keras.optimizers.Adam(learning_rate =0.0001), # lr is 10x lower while finetuning\n               metrics =['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:26.389751Z","iopub.execute_input":"2022-01-16T12:17:26.390387Z","iopub.status.idle":"2022-01-16T12:17:26.525014Z","shell.execute_reply.started":"2022-01-16T12:17:26.390304Z","shell.execute_reply":"2022-01-16T12:17:26.524152Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# check trainable layers of the base model\nfor layers_num, layer in enumerate(base_model.layers):\n    print(layers_num,layer.name,layer.trainable)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:26.526404Z","iopub.execute_input":"2022-01-16T12:17:26.526714Z","iopub.status.idle":"2022-01-16T12:17:26.663104Z","shell.execute_reply.started":"2022-01-16T12:17:26.526672Z","shell.execute_reply":"2022-01-16T12:17:26.662227Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"Nice! It seems all layers except for the last 10 are frozen and untrainable. This means only the last 10 layers of the base model along with the output layer will have their weights updated during training.\n\n\nEvery time you make a change to your models, you need to recompile them.\n\nIn our case, we're using the exact same loss, optimizer and metrics as before, except this time the learning rate for our optimizer will be 10x smaller than before (0.0001 instead of Adam's default of 0.001).\n\nWe do this so the model doesn't try to overwrite the existing weights in the pretrained model too fast. In other words, we want learning to be more gradual.","metadata":{}},{"cell_type":"code","source":"print(len(model_2.trainable_variables))","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:26.664572Z","iopub.execute_input":"2022-01-16T12:17:26.664928Z","iopub.status.idle":"2022-01-16T12:17:26.671407Z","shell.execute_reply.started":"2022-01-16T12:17:26.664887Z","shell.execute_reply":"2022-01-16T12:17:26.670168Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"fine_tine_epochs = initial_epochs  + 5\nhist_10_fine = model_2.fit(train_data_10,\n                          epochs=fine_tine_epochs,\n                          validation_data = test_data_10,\n                          initial_epoch = hist_10.epoch[-1], # start from the previous last epoch\n                          validation_steps= int(0.25 *len(test_data_10)),\n                          callbacks = check_callback)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:17:26.673269Z","iopub.execute_input":"2022-01-16T12:17:26.673987Z","iopub.status.idle":"2022-01-16T12:18:25.321693Z","shell.execute_reply.started":"2022-01-16T12:17:26.673942Z","shell.execute_reply":"2022-01-16T12:18:25.320666Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"results = model_2.evaluate(test_data_10)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:18:25.323436Z","iopub.execute_input":"2022-01-16T12:18:25.323749Z","iopub.status.idle":"2022-01-16T12:18:35.580849Z","shell.execute_reply.started":"2022-01-16T12:18:25.323709Z","shell.execute_reply":"2022-01-16T12:18:35.579474Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# comparing model performance before and after finetuning\ndef compare_historys(original_history,new_history,initial_epochs =5):\n    \"\"\"\n    compare two model history objects\n    \"\"\"\n    # get original history measurements\n    acc = original_history.history['accuracy']\n    loss = original_history.history['loss']\n    \n    print(len(acc))\n    \n    val_acc =original_history.history['val_accuracy']\n    val_loss = original_history.history['val_loss']\n    \n    # combine original history with new one\n    total_acc =acc+new_history.history['accuracy']\n    total_loss = loss+ new_history.history['loss']\n    \n    total_val_acc = val_acc + new_history.history['val_accuracy']\n    total_val_loss = val_loss + new_history.history['val_loss']\n    \n    print(len(total_acc))\n    \n    #plots\n    plt.figure(figsize=(8,8))\n    plt.subplot(2,1,1)\n    plt.plot(total_acc,label ='training accuracy')\n    plt.plot(total_val_acc, label='validation accuracy')\n    plt.plot([initial_epochs-1,initial_epochs-1], plt.ylim(),label='start fine tuning')\n    plt.legend(loc=\"lower right\")\n    plt.title(\"Training and validation accuracy\")\n\n    plt.subplot(2,1,2)\n    plt.plot(total_loss,label ='Training loss')\n    plt.plot(total_val_loss, label ='Validation loss')\n    plt.plot([initial_epochs-1,initial_epochs-1], plt.ylim(),label='start fine tuning')\n    plt.legend(loc=\"upper right\")\n    plt.title(\"Training and validation loss\")\n    plt.xlabel(\"epochs\")\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:18:35.582477Z","iopub.execute_input":"2022-01-16T12:18:35.584390Z","iopub.status.idle":"2022-01-16T12:18:35.596836Z","shell.execute_reply.started":"2022-01-16T12:18:35.584339Z","shell.execute_reply":"2022-01-16T12:18:35.595725Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"compare_historys(hist_10,hist_10_fine,initial_epochs=5)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:18:35.598166Z","iopub.execute_input":"2022-01-16T12:18:35.598752Z","iopub.status.idle":"2022-01-16T12:18:36.041444Z","shell.execute_reply.started":"2022-01-16T12:18:35.598709Z","shell.execute_reply":"2022-01-16T12:18:36.040501Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## Model 4: Fine-tuning an existing model all of the data\n\nEnough talk about how fine-tuning a model usually works with more data, let's try it out.\n\nWe'll start by downloading the full version of our 10 food classes dataset.\n","metadata":{}},{"cell_type":"code","source":"# Download and unzip 10 classes of data with all images\n!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip \nunzip_data(\"10_food_classes_all_data.zip\")\n\n# Setup data directories\ntrain_dir = \"10_food_classes_all_data/train/\"\ntest_dir = \"10_food_classes_all_data/test/\"","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:18:36.046671Z","iopub.execute_input":"2022-01-16T12:18:36.046935Z","iopub.status.idle":"2022-01-16T12:18:50.855166Z","shell.execute_reply.started":"2022-01-16T12:18:36.046887Z","shell.execute_reply":"2022-01-16T12:18:50.854039Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# How many images are we working with now?\nwalk_through_dir(\"10_food_classes_all_data\")","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:18:50.857371Z","iopub.execute_input":"2022-01-16T12:18:50.857873Z","iopub.status.idle":"2022-01-16T12:18:50.890258Z","shell.execute_reply.started":"2022-01-16T12:18:50.857822Z","shell.execute_reply":"2022-01-16T12:18:50.889283Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"## Setup data inputs\nimport tensorflow as tf\nIMG_SIZE = (224, 224)\ntrain_data= tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n                                                                                 label_mode=\"categorical\",\n                                                                                 image_size=IMG_SIZE)\n\n# Note: this is the same test dataset we've been using for the previous modelling experiments\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n                                                                label_mode=\"categorical\",\n                                                                image_size=IMG_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:18:50.892408Z","iopub.execute_input":"2022-01-16T12:18:50.893051Z","iopub.status.idle":"2022-01-16T12:18:51.712213Z","shell.execute_reply.started":"2022-01-16T12:18:50.893008Z","shell.execute_reply":"2022-01-16T12:18:51.710306Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# evaluate model on test data\nmodel_2.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:18:51.714187Z","iopub.execute_input":"2022-01-16T12:18:51.714581Z","iopub.status.idle":"2022-01-16T12:18:59.744740Z","shell.execute_reply.started":"2022-01-16T12:18:51.714521Z","shell.execute_reply":"2022-01-16T12:18:59.743200Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Load model from checkpoint, that way we can fine-tune from the same stage the 10 percent data model was fine-tuned from\nmodel_2.load_weights(checkpoint_path) # revert model back to saved weights","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:18:59.752391Z","iopub.execute_input":"2022-01-16T12:18:59.752764Z","iopub.status.idle":"2022-01-16T12:19:01.217910Z","shell.execute_reply.started":"2022-01-16T12:18:59.752711Z","shell.execute_reply":"2022-01-16T12:19:01.216945Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"model_2.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:19:01.219667Z","iopub.execute_input":"2022-01-16T12:19:01.220136Z","iopub.status.idle":"2022-01-16T12:19:07.911854Z","shell.execute_reply.started":"2022-01-16T12:19:01.220075Z","shell.execute_reply":"2022-01-16T12:19:07.910868Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Compile\nmodel_2.compile(loss=\"categorical_crossentropy\",\n                optimizer=tf.keras.optimizers.Adam(lr=0.0001), # divide learning rate by 10 for fine-tuning\n                metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:19:07.913746Z","iopub.execute_input":"2022-01-16T12:19:07.914869Z","iopub.status.idle":"2022-01-16T12:19:07.935875Z","shell.execute_reply.started":"2022-01-16T12:19:07.914824Z","shell.execute_reply":"2022-01-16T12:19:07.934953Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Continue to train and fine-tune the model to our data\nfine_tune_epochs = initial_epochs+10\n\nhistory_fine_10_classes_full = model_2.fit(train_data,\n                                           epochs=fine_tune_epochs,\n                                           initial_epoch=hist_10.epoch[-1],\n                                           validation_data=test_data,\n                                           validation_steps=int(0.25 * len(test_data)),\n                                           callbacks=[create_tensorboard_callback(\"transfer_learning\", \"full_10_classes_fine_tune_last_10\")])","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:19:26.845523Z","iopub.execute_input":"2022-01-16T12:19:26.846067Z","iopub.status.idle":"2022-01-16T12:25:13.140728Z","shell.execute_reply.started":"2022-01-16T12:19:26.846013Z","shell.execute_reply":"2022-01-16T12:25:13.139647Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"results_fine_tune_full_data = model_2.evaluate(test_data)\nresults_fine_tune_full_data","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:25:13.142868Z","iopub.execute_input":"2022-01-16T12:25:13.143187Z","iopub.status.idle":"2022-01-16T12:25:23.408784Z","shell.execute_reply.started":"2022-01-16T12:25:13.143146Z","shell.execute_reply":"2022-01-16T12:25:23.407638Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# How did fine-tuning go with more data?\ncompare_historys(original_history=hist_10,\n                 new_history=history_fine_10_classes_full,\n                 initial_epochs=5)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T12:26:26.157338Z","iopub.execute_input":"2022-01-16T12:26:26.157663Z","iopub.status.idle":"2022-01-16T12:26:26.617814Z","shell.execute_reply.started":"2022-01-16T12:26:26.157633Z","shell.execute_reply":"2022-01-16T12:26:26.616654Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}